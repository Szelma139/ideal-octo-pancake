---
layout: ../../layouts/MainLayout.astro
---

# Co warto znać aby być bossem ?


```ts 
frastructure: AWS, GCP, Azure, Kubernetes (this will increase as we go cloud-agnostic)
Platform: CockroachDB, EKS, GKE, PostgresDB, Vault, Consul, Linkerd, Cilium, NATS
Tools: Terraform, Github, Flux, Prometheus, Pact.io, TFSec, Travis CI
Code: Go, (a little Java), CQRS, Open-Source, Python (Security tools)
Ways of working: DevSecOps, GitOps, TDD/BDD, Pair Programming, 100% Remote

Experience in securing SDLCs, conducting SAST and DAST testing, threat modelling, code analysis and incident management. Our engineering teams are constantly developing new products that are added to our singular API gateway so the CI/CD pipeline must be secure by design.
Ability to create, deliver and enhance security of cloud-native distributed systems (we use AWS and GCP at present with Terraform as our Iac tool), following the best practices and implementing security controls post assessment. We are also looking to become cloud-agnostic meaning there will be opportunity for you to showcase your abilities across other cloud platforms.
Strong programming skills, we are flexible on languages, we use Go as our main language for production so a willingness or interest to learn Go is fundamental. In security we write our own scripts for automation in Python, Go and other languages while contributing to open-source tools so we can utilise them.
Familiarity with containerisation and microservices architecture security concepts is also crucial to being successful in this role.
Willingness to be part of the on-call rota.
 
DESIRABLES AND YOUR SPECIALISMS

SDLC Based:

3+ Years of expertise in Kubernetes, securing clusters and meshes (Cilium is preferable), networking best practices and RBAC implementation (CKA, CKS qualifications are a plus)
Experience in hardening Linux OSs
+3 Years of container security knowledge including container image provenance (Sigstore and Notary as examples) with an in-depth knowledge of container runtimes/ Docker and the security controls and best practice that surround microservice architectures
Involvement in DevSecOps operations within Agile environments on to CI/CD pipelines (Travis CI and Flux are our tools) with the ability to choose the right tool to fit purpose
Hands on work within agile DevOps environments that follow the DevSecOps best practices, where you expressed the ability to choose the right tool to fit purpose
CI/CD pipeline (Travis CI and Flux are our tools) security management
 
Wider Security:

Hands on experience taking your company through any of the following ISO27001, ISAE3000, SOC2/1, GDPR, PCI-DSS
Previous experience in developing security road maps and architectures alongside Security Architects in cloud-native or hybrid-infrastructures including network security (AWS solutions architect or GCP professional cloud architect are a plus)
Previous experience in network security, preferably in hybrid infrastructure based environments, you will have managed, switches, network segmentation, ports and firewalls across the entire OSI model.
 
Personal Interests:

Keen interest in new and emerging threats, vulnerabilities and adversary advancements coupled with the ability to present these to the wider team
Active contributor to open-source projects and passion for developing internal tools (our engineers were some of the main contributors for TFSec)
Additional Qualifications (nice to have but not necessary): OSCP, CASE, CCSP, AWS Security Specialist or GCP Professional Cloud Security Engineer 


6+ years of experience in Application Development and support
GCP knowledge and hands-on experience
Strong experience with coding and documenting on GCP BQ, GCS, VM, Load Balancing, Cloud SQL, and Managed Group VM instances
Knowledge of coding and maintaining/configuring Kubernetes PODs, Kubectl, YAML, Cloud
Experience in deploying microservices in Kubernetes PODs
SQL practical knowledge
Knowledge of the syntax of SQL Statements: Insert, Update or Delete
Experience with queries with sorting/grouping (such as group by, order by...) and queries using filters (where-clause)

 Senior DevOps/Network Engineer, ideally,you should meet the following criteria:
Good knowledge of public clouds (AWS/GCP/Azure)
Hands-on automation experience (Terraform)
Good knowledge of Linux and Kubernetes
Knowledge of a Scripting language (e.g. Python, Bash)
Fluency in English (B2 level minimum)
Work in the afternoon hours to better synchronize with US time zones might be required
Work with our tech stack, consisting of Git (Lab), Kubernetes, Docker, Terraform, Prometheus, Grafana, EFK Stack, and Argo CD 
Doświadczenie z integracją baz danych
Doświadczenie w implementacji rozwiązań architektonicznych i analizy danych w jednej z Chmur Publicznych (AWS, Azure, GCP, Oracle Cloud)
Migracja danych między systemami legacy, a chmurą publiczną (np. Hadoop, Exadata, Teradata, Netezza)
Hurtownie danych, ETL, Data Lake
Projektowanie i utrzymanie elementów Hadoop stack (np. MapReduce, Sqoop, Pig, Hive, HBase, Flume, Spark, Kafka, Flink, Java)
Znajomość baz danych SQL/NoSQL (np. Oracle, PostgreSQL, MySQL, Cassandra, MongoDB)
operation result
```